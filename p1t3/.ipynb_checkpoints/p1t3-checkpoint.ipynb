{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b90d7e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.databricks:spark-xml_2.12:0.14.0 pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1b381fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/usr/lib/spark/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      "com.databricks#spark-xml_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-bf08e729-a62c-4147-8eb8-0016bcb4687b;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.databricks#spark-xml_2.12;0.14.0 in central\n",
      "\tfound commons-io#commons-io;2.8.0 in central\n",
      "\tfound org.glassfish.jaxb#txw2;2.3.4 in central\n",
      "\tfound org.apache.ws.xmlschema#xmlschema-core;2.2.5 in central\n",
      ":: resolution report :: resolve 267ms :: artifacts dl 7ms\n",
      "\t:: modules in use:\n",
      "\tcom.databricks#spark-xml_2.12;0.14.0 from central in [default]\n",
      "\tcommons-io#commons-io;2.8.0 from central in [default]\n",
      "\torg.apache.ws.xmlschema#xmlschema-core;2.2.5 from central in [default]\n",
      "\torg.glassfish.jaxb#txw2;2.3.4 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   4   |   0   |   0   |   0   ||   4   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-bf08e729-a62c-4147-8eb8-0016bcb4687b\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 4 already retrieved (0kB/8ms)\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/04/20 00:07:44 INFO org.apache.spark.SparkEnv: Registering MapOutputTracker\n",
      "22/04/20 00:07:44 INFO org.apache.spark.SparkEnv: Registering BlockManagerMaster\n",
      "22/04/20 00:07:44 INFO org.apache.spark.SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "22/04/20 00:07:44 INFO org.apache.spark.SparkEnv: Registering OutputCommitCoordinator\n",
      "22/04/20 00:07:46 WARN org.apache.spark.deploy.yarn.Client: Same path resource file:///root/.ivy2/jars/com.databricks_spark-xml_2.12-0.14.0.jar added multiple times to distributed cache.\n",
      "22/04/20 00:07:46 WARN org.apache.spark.deploy.yarn.Client: Same path resource file:///root/.ivy2/jars/commons-io_commons-io-2.8.0.jar added multiple times to distributed cache.\n",
      "22/04/20 00:07:46 WARN org.apache.spark.deploy.yarn.Client: Same path resource file:///root/.ivy2/jars/org.glassfish.jaxb_txw2-2.3.4.jar added multiple times to distributed cache.\n",
      "22/04/20 00:07:46 WARN org.apache.spark.deploy.yarn.Client: Same path resource file:///root/.ivy2/jars/org.apache.ws.xmlschema_xmlschema-core-2.2.5.jar added multiple times to distributed cache.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "df = spark.read.option(\"delimiter\", \"\\t\").csv('hdfs://hw2-m/user/root/p1t2_small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "353f29f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/04/20 00:08:13 WARN org.apache.spark.deploy.yarn.YarnAllocator: Container from a bad node: container_1650379967059_0008_01_000001 on host: hw2-w-1.c.csee4121-339916.internal. Exit status: 134. Diagnostics: [2022-04-20 00:08:13.239]Exception from container-launch.\n",
      "Container id: container_1650379967059_0008_01_000001\n",
      "Exit code: 134\n",
      "\n",
      "[2022-04-20 00:08:13.242]Container exited with a non-zero exit code 134. Error file: prelaunch.err.\n",
      "Last 4096 bytes of prelaunch.err :\n",
      "/bin/bash: line 1: 19489 Aborted                 /usr/lib/jvm/temurin-8-jdk-amd64/bin/java -server -Xmx5739m -Djava.io.tmpdir=/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000001/tmp '-Dspark.driver.port=35073' '-Dspark.ui.port=0' '-Dspark.rpc.message.maxSize=512' -Dspark.yarn.app.container.log.dir=/var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000001 -XX:OnOutOfMemoryError='kill %p' org.apache.spark.executor.YarnCoarseGrainedExecutorBackend --driver-url spark://CoarseGrainedScheduler@hw2-m.c.csee4121-339916.internal:35073 --executor-id 1 --hostname hw2-w-1.c.csee4121-339916.internal --cores 2 --app-id application_1650379967059_0008 --resourceProfileId 0 --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000001/__app__.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000001/com.databricks_spark-xml_2.12-0.14.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000001/commons-io_commons-io-2.8.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000001/org.glassfish.jaxb_txw2-2.3.4.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000001/org.apache.ws.xmlschema_xmlschema-core-2.2.5.jar > /var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000001/stdout 2> /var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000001/stderr\n",
      "Last 4096 bytes of stderr :\n",
      "\n",
      "\n",
      "[2022-04-20 00:08:13.242]Container exited with a non-zero exit code 134. Error file: prelaunch.err.\n",
      "Last 4096 bytes of prelaunch.err :\n",
      "/bin/bash: line 1: 19489 Aborted                 /usr/lib/jvm/temurin-8-jdk-amd64/bin/java -server -Xmx5739m -Djava.io.tmpdir=/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000001/tmp '-Dspark.driver.port=35073' '-Dspark.ui.port=0' '-Dspark.rpc.message.maxSize=512' -Dspark.yarn.app.container.log.dir=/var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000001 -XX:OnOutOfMemoryError='kill %p' org.apache.spark.executor.YarnCoarseGrainedExecutorBackend --driver-url spark://CoarseGrainedScheduler@hw2-m.c.csee4121-339916.internal:35073 --executor-id 1 --hostname hw2-w-1.c.csee4121-339916.internal --cores 2 --app-id application_1650379967059_0008 --resourceProfileId 0 --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000001/__app__.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000001/com.databricks_spark-xml_2.12-0.14.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000001/commons-io_commons-io-2.8.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000001/org.glassfish.jaxb_txw2-2.3.4.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000001/org.apache.ws.xmlschema_xmlschema-core-2.2.5.jar > /var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000001/stdout 2> /var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000001/stderr\n",
      "Last 4096 bytes of stderr :\n",
      "\n",
      "\n",
      ".\n",
      "22/04/20 00:08:13 WARN org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 1 for reason Container from a bad node: container_1650379967059_0008_01_000001 on host: hw2-w-1.c.csee4121-339916.internal. Exit status: 134. Diagnostics: [2022-04-20 00:08:13.239]Exception from container-launch.\n",
      "Container id: container_1650379967059_0008_01_000001\n",
      "Exit code: 134\n",
      "\n",
      "[2022-04-20 00:08:13.242]Container exited with a non-zero exit code 134. Error file: prelaunch.err.\n",
      "Last 4096 bytes of prelaunch.err :\n",
      "/bin/bash: line 1: 19489 Aborted                 /usr/lib/jvm/temurin-8-jdk-amd64/bin/java -server -Xmx5739m -Djava.io.tmpdir=/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000001/tmp '-Dspark.driver.port=35073' '-Dspark.ui.port=0' '-Dspark.rpc.message.maxSize=512' -Dspark.yarn.app.container.log.dir=/var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000001 -XX:OnOutOfMemoryError='kill %p' org.apache.spark.executor.YarnCoarseGrainedExecutorBackend --driver-url spark://CoarseGrainedScheduler@hw2-m.c.csee4121-339916.internal:35073 --executor-id 1 --hostname hw2-w-1.c.csee4121-339916.internal --cores 2 --app-id application_1650379967059_0008 --resourceProfileId 0 --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000001/__app__.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000001/com.databricks_spark-xml_2.12-0.14.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000001/commons-io_commons-io-2.8.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000001/org.glassfish.jaxb_txw2-2.3.4.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000001/org.apache.ws.xmlschema_xmlschema-core-2.2.5.jar > /var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000001/stdout 2> /var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000001/stderr\n",
      "Last 4096 bytes of stderr :\n",
      "\n",
      "\n",
      "[2022-04-20 00:08:13.242]Container exited with a non-zero exit code 134. Error file: prelaunch.err.\n",
      "Last 4096 bytes of prelaunch.err :\n",
      "/bin/bash: line 1: 19489 Aborted                 /usr/lib/jvm/temurin-8-jdk-amd64/bin/java -server -Xmx5739m -Djava.io.tmpdir=/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000001/tmp '-Dspark.driver.port=35073' '-Dspark.ui.port=0' '-Dspark.rpc.message.maxSize=512' -Dspark.yarn.app.container.log.dir=/var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000001 -XX:OnOutOfMemoryError='kill %p' org.apache.spark.executor.YarnCoarseGrainedExecutorBackend --driver-url spark://CoarseGrainedScheduler@hw2-m.c.csee4121-339916.internal:35073 --executor-id 1 --hostname hw2-w-1.c.csee4121-339916.internal --cores 2 --app-id application_1650379967059_0008 --resourceProfileId 0 --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000001/__app__.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000001/com.databricks_spark-xml_2.12-0.14.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000001/commons-io_commons-io-2.8.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000001/org.glassfish.jaxb_txw2-2.3.4.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000001/org.apache.ws.xmlschema_xmlschema-core-2.2.5.jar > /var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000001/stdout 2> /var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000001/stderr\n",
      "Last 4096 bytes of stderr :\n",
      "\n",
      "\n",
      ".\n",
      "22/04/20 00:08:13 ERROR org.apache.spark.scheduler.cluster.YarnScheduler: Lost executor 1 on hw2-w-1.c.csee4121-339916.internal: Container from a bad node: container_1650379967059_0008_01_000001 on host: hw2-w-1.c.csee4121-339916.internal. Exit status: 134. Diagnostics: [2022-04-20 00:08:13.239]Exception from container-launch.\n",
      "Container id: container_1650379967059_0008_01_000001\n",
      "Exit code: 134\n",
      "\n",
      "[2022-04-20 00:08:13.242]Container exited with a non-zero exit code 134. Error file: prelaunch.err.\n",
      "Last 4096 bytes of prelaunch.err :\n",
      "/bin/bash: line 1: 19489 Aborted                 /usr/lib/jvm/temurin-8-jdk-amd64/bin/java -server -Xmx5739m -Djava.io.tmpdir=/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000001/tmp '-Dspark.driver.port=35073' '-Dspark.ui.port=0' '-Dspark.rpc.message.maxSize=512' -Dspark.yarn.app.container.log.dir=/var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000001 -XX:OnOutOfMemoryError='kill %p' org.apache.spark.executor.YarnCoarseGrainedExecutorBackend --driver-url spark://CoarseGrainedScheduler@hw2-m.c.csee4121-339916.internal:35073 --executor-id 1 --hostname hw2-w-1.c.csee4121-339916.internal --cores 2 --app-id application_1650379967059_0008 --resourceProfileId 0 --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000001/__app__.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000001/com.databricks_spark-xml_2.12-0.14.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000001/commons-io_commons-io-2.8.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000001/org.glassfish.jaxb_txw2-2.3.4.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000001/org.apache.ws.xmlschema_xmlschema-core-2.2.5.jar > /var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000001/stdout 2> /var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000001/stderr\n",
      "Last 4096 bytes of stderr :\n",
      "\n",
      "\n",
      "[2022-04-20 00:08:13.242]Container exited with a non-zero exit code 134. Error file: prelaunch.err.\n",
      "Last 4096 bytes of prelaunch.err :\n",
      "/bin/bash: line 1: 19489 Aborted                 /usr/lib/jvm/temurin-8-jdk-amd64/bin/java -server -Xmx5739m -Djava.io.tmpdir=/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000001/tmp '-Dspark.driver.port=35073' '-Dspark.ui.port=0' '-Dspark.rpc.message.maxSize=512' -Dspark.yarn.app.container.log.dir=/var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000001 -XX:OnOutOfMemoryError='kill %p' org.apache.spark.executor.YarnCoarseGrainedExecutorBackend --driver-url spark://CoarseGrainedScheduler@hw2-m.c.csee4121-339916.internal:35073 --executor-id 1 --hostname hw2-w-1.c.csee4121-339916.internal --cores 2 --app-id application_1650379967059_0008 --resourceProfileId 0 --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000001/__app__.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000001/com.databricks_spark-xml_2.12-0.14.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000001/commons-io_commons-io-2.8.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000001/org.glassfish.jaxb_txw2-2.3.4.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000001/org.apache.ws.xmlschema_xmlschema-core-2.2.5.jar > /var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000001/stdout 2> /var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000001/stderr\n",
      "Last 4096 bytes of stderr :\n",
      "\n",
      "\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "\n",
    "df_count = df.groupBy(\"_c0\").count()\n",
    "newdf = df_count.withColumn(\"rank\", lit(1))\n",
    "newdf = newdf.rdd.map(lambda x: (x[0], x[1], x[2], x[2]/x[1])).toDF(['article', 'count', 'rank', 'contribution'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aaef07b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 5:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+----+--------------------+\n",
      "|             article|count|rank|        contribution|\n",
      "+--------------------+-----+----+--------------------+\n",
      "|           amplifier|  115|   1|0.008695652173913044|\n",
      "|       alligatoridae|   85|   1|0.011764705882352941|\n",
      "|            april 24|  549|   1|0.001821493624772...|\n",
      "|               1970s|  783|   1|0.001277139208173691|\n",
      "|                1436|   65|   1|0.015384615384615385|\n",
      "|               anime|  226|   1|0.004424778761061947|\n",
      "|               aruba|  226|   1|0.004424778761061947|\n",
      "|  batman (1989 film)|  398|   1|0.002512562814070352|\n",
      "|              202 bc|   51|   1|  0.0196078431372549|\n",
      "|baton rouge, loui...|  345|   1|0.002898550724637681|\n",
      "|                1572|  188|   1|0.005319148936170213|\n",
      "|                1512|   98|   1| 0.01020408163265306|\n",
      "|  ancient philosophy|  284|   1|0.003521126760563...|\n",
      "|               97 bc|   29|   1|0.034482758620689655|\n",
      "|american airlines...|  202|   1|0.004950495049504...|\n",
      "|                 art|  255|   1| 0.00392156862745098|\n",
      "|                 675|   36|   1|0.027777777777777776|\n",
      "|                 467|   17|   1|0.058823529411764705|\n",
      "|         amblygonite|   41|   1|0.024390243902439025|\n",
      "|        bacteriology|    1|   1|                 1.0|\n",
      "+--------------------+-----+----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "newdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "beeb8590",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/04/20 00:09:05 WARN org.apache.spark.deploy.yarn.YarnAllocator: Container from a bad node: container_1650379967059_0008_01_000004 on host: hw2-w-1.c.csee4121-339916.internal. Exit status: 134. Diagnostics: [2022-04-20 00:09:05.646]Exception from container-launch.\n",
      "Container id: container_1650379967059_0008_01_000004\n",
      "Exit code: 134\n",
      "\n",
      "[2022-04-20 00:09:05.648]Container exited with a non-zero exit code 134. Error file: prelaunch.err.\n",
      "Last 4096 bytes of prelaunch.err :\n",
      "/bin/bash: line 1: 19546 Aborted                 /usr/lib/jvm/temurin-8-jdk-amd64/bin/java -server -Xmx5739m -Djava.io.tmpdir=/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000004/tmp '-Dspark.driver.port=35073' '-Dspark.ui.port=0' '-Dspark.rpc.message.maxSize=512' -Dspark.yarn.app.container.log.dir=/var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000004 -XX:OnOutOfMemoryError='kill %p' org.apache.spark.executor.YarnCoarseGrainedExecutorBackend --driver-url spark://CoarseGrainedScheduler@hw2-m.c.csee4121-339916.internal:35073 --executor-id 3 --hostname hw2-w-1.c.csee4121-339916.internal --cores 2 --app-id application_1650379967059_0008 --resourceProfileId 0 --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000004/__app__.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000004/com.databricks_spark-xml_2.12-0.14.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000004/commons-io_commons-io-2.8.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000004/org.glassfish.jaxb_txw2-2.3.4.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000004/org.apache.ws.xmlschema_xmlschema-core-2.2.5.jar > /var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000004/stdout 2> /var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000004/stderr\n",
      "Last 4096 bytes of stderr :\n",
      "\n",
      "\n",
      "[2022-04-20 00:09:05.649]Container exited with a non-zero exit code 134. Error file: prelaunch.err.\n",
      "Last 4096 bytes of prelaunch.err :\n",
      "/bin/bash: line 1: 19546 Aborted                 /usr/lib/jvm/temurin-8-jdk-amd64/bin/java -server -Xmx5739m -Djava.io.tmpdir=/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000004/tmp '-Dspark.driver.port=35073' '-Dspark.ui.port=0' '-Dspark.rpc.message.maxSize=512' -Dspark.yarn.app.container.log.dir=/var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000004 -XX:OnOutOfMemoryError='kill %p' org.apache.spark.executor.YarnCoarseGrainedExecutorBackend --driver-url spark://CoarseGrainedScheduler@hw2-m.c.csee4121-339916.internal:35073 --executor-id 3 --hostname hw2-w-1.c.csee4121-339916.internal --cores 2 --app-id application_1650379967059_0008 --resourceProfileId 0 --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000004/__app__.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000004/com.databricks_spark-xml_2.12-0.14.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000004/commons-io_commons-io-2.8.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000004/org.glassfish.jaxb_txw2-2.3.4.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000004/org.apache.ws.xmlschema_xmlschema-core-2.2.5.jar > /var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000004/stdout 2> /var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000004/stderr\n",
      "Last 4096 bytes of stderr :\n",
      "\n",
      "\n",
      ".\n",
      "22/04/20 00:09:05 WARN org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 3 for reason Container from a bad node: container_1650379967059_0008_01_000004 on host: hw2-w-1.c.csee4121-339916.internal. Exit status: 134. Diagnostics: [2022-04-20 00:09:05.646]Exception from container-launch.\n",
      "Container id: container_1650379967059_0008_01_000004\n",
      "Exit code: 134\n",
      "\n",
      "[2022-04-20 00:09:05.648]Container exited with a non-zero exit code 134. Error file: prelaunch.err.\n",
      "Last 4096 bytes of prelaunch.err :\n",
      "/bin/bash: line 1: 19546 Aborted                 /usr/lib/jvm/temurin-8-jdk-amd64/bin/java -server -Xmx5739m -Djava.io.tmpdir=/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000004/tmp '-Dspark.driver.port=35073' '-Dspark.ui.port=0' '-Dspark.rpc.message.maxSize=512' -Dspark.yarn.app.container.log.dir=/var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000004 -XX:OnOutOfMemoryError='kill %p' org.apache.spark.executor.YarnCoarseGrainedExecutorBackend --driver-url spark://CoarseGrainedScheduler@hw2-m.c.csee4121-339916.internal:35073 --executor-id 3 --hostname hw2-w-1.c.csee4121-339916.internal --cores 2 --app-id application_1650379967059_0008 --resourceProfileId 0 --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000004/__app__.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000004/com.databricks_spark-xml_2.12-0.14.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000004/commons-io_commons-io-2.8.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000004/org.glassfish.jaxb_txw2-2.3.4.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000004/org.apache.ws.xmlschema_xmlschema-core-2.2.5.jar > /var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000004/stdout 2> /var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000004/stderr\n",
      "Last 4096 bytes of stderr :\n",
      "\n",
      "\n",
      "[2022-04-20 00:09:05.649]Container exited with a non-zero exit code 134. Error file: prelaunch.err.\n",
      "Last 4096 bytes of prelaunch.err :\n",
      "/bin/bash: line 1: 19546 Aborted                 /usr/lib/jvm/temurin-8-jdk-amd64/bin/java -server -Xmx5739m -Djava.io.tmpdir=/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000004/tmp '-Dspark.driver.port=35073' '-Dspark.ui.port=0' '-Dspark.rpc.message.maxSize=512' -Dspark.yarn.app.container.log.dir=/var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000004 -XX:OnOutOfMemoryError='kill %p' org.apache.spark.executor.YarnCoarseGrainedExecutorBackend --driver-url spark://CoarseGrainedScheduler@hw2-m.c.csee4121-339916.internal:35073 --executor-id 3 --hostname hw2-w-1.c.csee4121-339916.internal --cores 2 --app-id application_1650379967059_0008 --resourceProfileId 0 --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000004/__app__.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000004/com.databricks_spark-xml_2.12-0.14.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000004/commons-io_commons-io-2.8.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000004/org.glassfish.jaxb_txw2-2.3.4.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000004/org.apache.ws.xmlschema_xmlschema-core-2.2.5.jar > /var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000004/stdout 2> /var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000004/stderr\n",
      "Last 4096 bytes of stderr :\n",
      "\n",
      "\n",
      ".\n",
      "22/04/20 00:09:05 ERROR org.apache.spark.scheduler.cluster.YarnScheduler: Lost executor 3 on hw2-w-1.c.csee4121-339916.internal: Container from a bad node: container_1650379967059_0008_01_000004 on host: hw2-w-1.c.csee4121-339916.internal. Exit status: 134. Diagnostics: [2022-04-20 00:09:05.646]Exception from container-launch.\n",
      "Container id: container_1650379967059_0008_01_000004\n",
      "Exit code: 134\n",
      "\n",
      "[2022-04-20 00:09:05.648]Container exited with a non-zero exit code 134. Error file: prelaunch.err.\n",
      "Last 4096 bytes of prelaunch.err :\n",
      "/bin/bash: line 1: 19546 Aborted                 /usr/lib/jvm/temurin-8-jdk-amd64/bin/java -server -Xmx5739m -Djava.io.tmpdir=/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000004/tmp '-Dspark.driver.port=35073' '-Dspark.ui.port=0' '-Dspark.rpc.message.maxSize=512' -Dspark.yarn.app.container.log.dir=/var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000004 -XX:OnOutOfMemoryError='kill %p' org.apache.spark.executor.YarnCoarseGrainedExecutorBackend --driver-url spark://CoarseGrainedScheduler@hw2-m.c.csee4121-339916.internal:35073 --executor-id 3 --hostname hw2-w-1.c.csee4121-339916.internal --cores 2 --app-id application_1650379967059_0008 --resourceProfileId 0 --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000004/__app__.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000004/com.databricks_spark-xml_2.12-0.14.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000004/commons-io_commons-io-2.8.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000004/org.glassfish.jaxb_txw2-2.3.4.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000004/org.apache.ws.xmlschema_xmlschema-core-2.2.5.jar > /var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000004/stdout 2> /var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000004/stderr\n",
      "Last 4096 bytes of stderr :\n",
      "\n",
      "\n",
      "[2022-04-20 00:09:05.649]Container exited with a non-zero exit code 134. Error file: prelaunch.err.\n",
      "Last 4096 bytes of prelaunch.err :\n",
      "/bin/bash: line 1: 19546 Aborted                 /usr/lib/jvm/temurin-8-jdk-amd64/bin/java -server -Xmx5739m -Djava.io.tmpdir=/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000004/tmp '-Dspark.driver.port=35073' '-Dspark.ui.port=0' '-Dspark.rpc.message.maxSize=512' -Dspark.yarn.app.container.log.dir=/var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000004 -XX:OnOutOfMemoryError='kill %p' org.apache.spark.executor.YarnCoarseGrainedExecutorBackend --driver-url spark://CoarseGrainedScheduler@hw2-m.c.csee4121-339916.internal:35073 --executor-id 3 --hostname hw2-w-1.c.csee4121-339916.internal --cores 2 --app-id application_1650379967059_0008 --resourceProfileId 0 --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000004/__app__.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000004/com.databricks_spark-xml_2.12-0.14.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000004/commons-io_commons-io-2.8.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000004/org.glassfish.jaxb_txw2-2.3.4.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000004/org.apache.ws.xmlschema_xmlschema-core-2.2.5.jar > /var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000004/stdout 2> /var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000004/stderr\n",
      "Last 4096 bytes of stderr :\n",
      "\n",
      "\n",
      ".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/04/20 00:09:21 WARN org.apache.spark.deploy.yarn.YarnAllocator: Container from a bad node: container_1650379967059_0008_01_000006 on host: hw2-w-1.c.csee4121-339916.internal. Exit status: 134. Diagnostics: [2022-04-20 00:09:21.043]Exception from container-launch.\n",
      "Container id: container_1650379967059_0008_01_000006\n",
      "Exit code: 134\n",
      "\n",
      "[2022-04-20 00:09:21.046]Container exited with a non-zero exit code 134. Error file: prelaunch.err.\n",
      "Last 4096 bytes of prelaunch.err :\n",
      "/bin/bash: line 1: 19778 Aborted                 /usr/lib/jvm/temurin-8-jdk-amd64/bin/java -server -Xmx5739m -Djava.io.tmpdir=/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000006/tmp '-Dspark.driver.port=35073' '-Dspark.ui.port=0' '-Dspark.rpc.message.maxSize=512' -Dspark.yarn.app.container.log.dir=/var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000006 -XX:OnOutOfMemoryError='kill %p' org.apache.spark.executor.YarnCoarseGrainedExecutorBackend --driver-url spark://CoarseGrainedScheduler@hw2-m.c.csee4121-339916.internal:35073 --executor-id 5 --hostname hw2-w-1.c.csee4121-339916.internal --cores 2 --app-id application_1650379967059_0008 --resourceProfileId 0 --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000006/__app__.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000006/com.databricks_spark-xml_2.12-0.14.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000006/commons-io_commons-io-2.8.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000006/org.glassfish.jaxb_txw2-2.3.4.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000006/org.apache.ws.xmlschema_xmlschema-core-2.2.5.jar > /var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000006/stdout 2> /var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000006/stderr\n",
      "Last 4096 bytes of stderr :\n",
      "\n",
      "\n",
      "[2022-04-20 00:09:21.046]Container exited with a non-zero exit code 134. Error file: prelaunch.err.\n",
      "Last 4096 bytes of prelaunch.err :\n",
      "/bin/bash: line 1: 19778 Aborted                 /usr/lib/jvm/temurin-8-jdk-amd64/bin/java -server -Xmx5739m -Djava.io.tmpdir=/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000006/tmp '-Dspark.driver.port=35073' '-Dspark.ui.port=0' '-Dspark.rpc.message.maxSize=512' -Dspark.yarn.app.container.log.dir=/var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000006 -XX:OnOutOfMemoryError='kill %p' org.apache.spark.executor.YarnCoarseGrainedExecutorBackend --driver-url spark://CoarseGrainedScheduler@hw2-m.c.csee4121-339916.internal:35073 --executor-id 5 --hostname hw2-w-1.c.csee4121-339916.internal --cores 2 --app-id application_1650379967059_0008 --resourceProfileId 0 --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000006/__app__.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000006/com.databricks_spark-xml_2.12-0.14.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000006/commons-io_commons-io-2.8.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000006/org.glassfish.jaxb_txw2-2.3.4.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000006/org.apache.ws.xmlschema_xmlschema-core-2.2.5.jar > /var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000006/stdout 2> /var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000006/stderr\n",
      "Last 4096 bytes of stderr :\n",
      "\n",
      "\n",
      ".\n",
      "22/04/20 00:09:21 WARN org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 5 for reason Container from a bad node: container_1650379967059_0008_01_000006 on host: hw2-w-1.c.csee4121-339916.internal. Exit status: 134. Diagnostics: [2022-04-20 00:09:21.043]Exception from container-launch.\n",
      "Container id: container_1650379967059_0008_01_000006\n",
      "Exit code: 134\n",
      "\n",
      "[2022-04-20 00:09:21.046]Container exited with a non-zero exit code 134. Error file: prelaunch.err.\n",
      "Last 4096 bytes of prelaunch.err :\n",
      "/bin/bash: line 1: 19778 Aborted                 /usr/lib/jvm/temurin-8-jdk-amd64/bin/java -server -Xmx5739m -Djava.io.tmpdir=/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000006/tmp '-Dspark.driver.port=35073' '-Dspark.ui.port=0' '-Dspark.rpc.message.maxSize=512' -Dspark.yarn.app.container.log.dir=/var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000006 -XX:OnOutOfMemoryError='kill %p' org.apache.spark.executor.YarnCoarseGrainedExecutorBackend --driver-url spark://CoarseGrainedScheduler@hw2-m.c.csee4121-339916.internal:35073 --executor-id 5 --hostname hw2-w-1.c.csee4121-339916.internal --cores 2 --app-id application_1650379967059_0008 --resourceProfileId 0 --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000006/__app__.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000006/com.databricks_spark-xml_2.12-0.14.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000006/commons-io_commons-io-2.8.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000006/org.glassfish.jaxb_txw2-2.3.4.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000006/org.apache.ws.xmlschema_xmlschema-core-2.2.5.jar > /var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000006/stdout 2> /var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000006/stderr\n",
      "Last 4096 bytes of stderr :\n",
      "\n",
      "\n",
      "[2022-04-20 00:09:21.046]Container exited with a non-zero exit code 134. Error file: prelaunch.err.\n",
      "Last 4096 bytes of prelaunch.err :\n",
      "/bin/bash: line 1: 19778 Aborted                 /usr/lib/jvm/temurin-8-jdk-amd64/bin/java -server -Xmx5739m -Djava.io.tmpdir=/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000006/tmp '-Dspark.driver.port=35073' '-Dspark.ui.port=0' '-Dspark.rpc.message.maxSize=512' -Dspark.yarn.app.container.log.dir=/var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000006 -XX:OnOutOfMemoryError='kill %p' org.apache.spark.executor.YarnCoarseGrainedExecutorBackend --driver-url spark://CoarseGrainedScheduler@hw2-m.c.csee4121-339916.internal:35073 --executor-id 5 --hostname hw2-w-1.c.csee4121-339916.internal --cores 2 --app-id application_1650379967059_0008 --resourceProfileId 0 --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000006/__app__.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000006/com.databricks_spark-xml_2.12-0.14.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000006/commons-io_commons-io-2.8.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000006/org.glassfish.jaxb_txw2-2.3.4.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000006/org.apache.ws.xmlschema_xmlschema-core-2.2.5.jar > /var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000006/stdout 2> /var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000006/stderr\n",
      "Last 4096 bytes of stderr :\n",
      "\n",
      "\n",
      ".\n",
      "22/04/20 00:09:21 ERROR org.apache.spark.scheduler.cluster.YarnScheduler: Lost executor 5 on hw2-w-1.c.csee4121-339916.internal: Container from a bad node: container_1650379967059_0008_01_000006 on host: hw2-w-1.c.csee4121-339916.internal. Exit status: 134. Diagnostics: [2022-04-20 00:09:21.043]Exception from container-launch.\n",
      "Container id: container_1650379967059_0008_01_000006\n",
      "Exit code: 134\n",
      "\n",
      "[2022-04-20 00:09:21.046]Container exited with a non-zero exit code 134. Error file: prelaunch.err.\n",
      "Last 4096 bytes of prelaunch.err :\n",
      "/bin/bash: line 1: 19778 Aborted                 /usr/lib/jvm/temurin-8-jdk-amd64/bin/java -server -Xmx5739m -Djava.io.tmpdir=/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000006/tmp '-Dspark.driver.port=35073' '-Dspark.ui.port=0' '-Dspark.rpc.message.maxSize=512' -Dspark.yarn.app.container.log.dir=/var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000006 -XX:OnOutOfMemoryError='kill %p' org.apache.spark.executor.YarnCoarseGrainedExecutorBackend --driver-url spark://CoarseGrainedScheduler@hw2-m.c.csee4121-339916.internal:35073 --executor-id 5 --hostname hw2-w-1.c.csee4121-339916.internal --cores 2 --app-id application_1650379967059_0008 --resourceProfileId 0 --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000006/__app__.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000006/com.databricks_spark-xml_2.12-0.14.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000006/commons-io_commons-io-2.8.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000006/org.glassfish.jaxb_txw2-2.3.4.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000006/org.apache.ws.xmlschema_xmlschema-core-2.2.5.jar > /var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000006/stdout 2> /var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000006/stderr\n",
      "Last 4096 bytes of stderr :\n",
      "\n",
      "\n",
      "[2022-04-20 00:09:21.046]Container exited with a non-zero exit code 134. Error file: prelaunch.err.\n",
      "Last 4096 bytes of prelaunch.err :\n",
      "/bin/bash: line 1: 19778 Aborted                 /usr/lib/jvm/temurin-8-jdk-amd64/bin/java -server -Xmx5739m -Djava.io.tmpdir=/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000006/tmp '-Dspark.driver.port=35073' '-Dspark.ui.port=0' '-Dspark.rpc.message.maxSize=512' -Dspark.yarn.app.container.log.dir=/var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000006 -XX:OnOutOfMemoryError='kill %p' org.apache.spark.executor.YarnCoarseGrainedExecutorBackend --driver-url spark://CoarseGrainedScheduler@hw2-m.c.csee4121-339916.internal:35073 --executor-id 5 --hostname hw2-w-1.c.csee4121-339916.internal --cores 2 --app-id application_1650379967059_0008 --resourceProfileId 0 --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000006/__app__.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000006/com.databricks_spark-xml_2.12-0.14.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000006/commons-io_commons-io-2.8.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000006/org.glassfish.jaxb_txw2-2.3.4.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000006/org.apache.ws.xmlschema_xmlschema-core-2.2.5.jar > /var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000006/stdout 2> /var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000006/stderr\n",
      "Last 4096 bytes of stderr :\n",
      "\n",
      "\n",
      ".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/04/20 00:09:38 WARN org.apache.spark.deploy.yarn.YarnAllocator: Container from a bad node: container_1650379967059_0008_01_000005 on host: hw2-w-1.c.csee4121-339916.internal. Exit status: 134. Diagnostics: [2022-04-20 00:09:38.255]Exception from container-launch.\n",
      "Container id: container_1650379967059_0008_01_000005\n",
      "Exit code: 134\n",
      "\n",
      "[2022-04-20 00:09:38.257]Container exited with a non-zero exit code 134. Error file: prelaunch.err.\n",
      "Last 4096 bytes of prelaunch.err :\n",
      "/bin/bash: line 1: 19630 Aborted                 /usr/lib/jvm/temurin-8-jdk-amd64/bin/java -server -Xmx5739m -Djava.io.tmpdir=/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000005/tmp '-Dspark.driver.port=35073' '-Dspark.ui.port=0' '-Dspark.rpc.message.maxSize=512' -Dspark.yarn.app.container.log.dir=/var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000005 -XX:OnOutOfMemoryError='kill %p' org.apache.spark.executor.YarnCoarseGrainedExecutorBackend --driver-url spark://CoarseGrainedScheduler@hw2-m.c.csee4121-339916.internal:35073 --executor-id 4 --hostname hw2-w-1.c.csee4121-339916.internal --cores 2 --app-id application_1650379967059_0008 --resourceProfileId 0 --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000005/__app__.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000005/com.databricks_spark-xml_2.12-0.14.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000005/commons-io_commons-io-2.8.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000005/org.glassfish.jaxb_txw2-2.3.4.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000005/org.apache.ws.xmlschema_xmlschema-core-2.2.5.jar > /var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000005/stdout 2> /var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000005/stderr\n",
      "Last 4096 bytes of stderr :\n",
      "\n",
      "\n",
      "[2022-04-20 00:09:38.258]Container exited with a non-zero exit code 134. Error file: prelaunch.err.\n",
      "Last 4096 bytes of prelaunch.err :\n",
      "/bin/bash: line 1: 19630 Aborted                 /usr/lib/jvm/temurin-8-jdk-amd64/bin/java -server -Xmx5739m -Djava.io.tmpdir=/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000005/tmp '-Dspark.driver.port=35073' '-Dspark.ui.port=0' '-Dspark.rpc.message.maxSize=512' -Dspark.yarn.app.container.log.dir=/var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000005 -XX:OnOutOfMemoryError='kill %p' org.apache.spark.executor.YarnCoarseGrainedExecutorBackend --driver-url spark://CoarseGrainedScheduler@hw2-m.c.csee4121-339916.internal:35073 --executor-id 4 --hostname hw2-w-1.c.csee4121-339916.internal --cores 2 --app-id application_1650379967059_0008 --resourceProfileId 0 --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000005/__app__.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000005/com.databricks_spark-xml_2.12-0.14.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000005/commons-io_commons-io-2.8.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000005/org.glassfish.jaxb_txw2-2.3.4.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000005/org.apache.ws.xmlschema_xmlschema-core-2.2.5.jar > /var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000005/stdout 2> /var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000005/stderr\n",
      "Last 4096 bytes of stderr :\n",
      "\n",
      "\n",
      ".\n",
      "22/04/20 00:09:38 WARN org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 4 for reason Container from a bad node: container_1650379967059_0008_01_000005 on host: hw2-w-1.c.csee4121-339916.internal. Exit status: 134. Diagnostics: [2022-04-20 00:09:38.255]Exception from container-launch.\n",
      "Container id: container_1650379967059_0008_01_000005\n",
      "Exit code: 134\n",
      "\n",
      "[2022-04-20 00:09:38.257]Container exited with a non-zero exit code 134. Error file: prelaunch.err.\n",
      "Last 4096 bytes of prelaunch.err :\n",
      "/bin/bash: line 1: 19630 Aborted                 /usr/lib/jvm/temurin-8-jdk-amd64/bin/java -server -Xmx5739m -Djava.io.tmpdir=/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000005/tmp '-Dspark.driver.port=35073' '-Dspark.ui.port=0' '-Dspark.rpc.message.maxSize=512' -Dspark.yarn.app.container.log.dir=/var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000005 -XX:OnOutOfMemoryError='kill %p' org.apache.spark.executor.YarnCoarseGrainedExecutorBackend --driver-url spark://CoarseGrainedScheduler@hw2-m.c.csee4121-339916.internal:35073 --executor-id 4 --hostname hw2-w-1.c.csee4121-339916.internal --cores 2 --app-id application_1650379967059_0008 --resourceProfileId 0 --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000005/__app__.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000005/com.databricks_spark-xml_2.12-0.14.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000005/commons-io_commons-io-2.8.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000005/org.glassfish.jaxb_txw2-2.3.4.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000005/org.apache.ws.xmlschema_xmlschema-core-2.2.5.jar > /var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000005/stdout 2> /var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000005/stderr\n",
      "Last 4096 bytes of stderr :\n",
      "\n",
      "\n",
      "[2022-04-20 00:09:38.258]Container exited with a non-zero exit code 134. Error file: prelaunch.err.\n",
      "Last 4096 bytes of prelaunch.err :\n",
      "/bin/bash: line 1: 19630 Aborted                 /usr/lib/jvm/temurin-8-jdk-amd64/bin/java -server -Xmx5739m -Djava.io.tmpdir=/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000005/tmp '-Dspark.driver.port=35073' '-Dspark.ui.port=0' '-Dspark.rpc.message.maxSize=512' -Dspark.yarn.app.container.log.dir=/var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000005 -XX:OnOutOfMemoryError='kill %p' org.apache.spark.executor.YarnCoarseGrainedExecutorBackend --driver-url spark://CoarseGrainedScheduler@hw2-m.c.csee4121-339916.internal:35073 --executor-id 4 --hostname hw2-w-1.c.csee4121-339916.internal --cores 2 --app-id application_1650379967059_0008 --resourceProfileId 0 --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000005/__app__.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000005/com.databricks_spark-xml_2.12-0.14.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000005/commons-io_commons-io-2.8.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000005/org.glassfish.jaxb_txw2-2.3.4.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000005/org.apache.ws.xmlschema_xmlschema-core-2.2.5.jar > /var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000005/stdout 2> /var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000005/stderr\n",
      "Last 4096 bytes of stderr :\n",
      "\n",
      "\n",
      ".\n",
      "22/04/20 00:09:38 ERROR org.apache.spark.scheduler.cluster.YarnScheduler: Lost executor 4 on hw2-w-1.c.csee4121-339916.internal: Container from a bad node: container_1650379967059_0008_01_000005 on host: hw2-w-1.c.csee4121-339916.internal. Exit status: 134. Diagnostics: [2022-04-20 00:09:38.255]Exception from container-launch.\n",
      "Container id: container_1650379967059_0008_01_000005\n",
      "Exit code: 134\n",
      "\n",
      "[2022-04-20 00:09:38.257]Container exited with a non-zero exit code 134. Error file: prelaunch.err.\n",
      "Last 4096 bytes of prelaunch.err :\n",
      "/bin/bash: line 1: 19630 Aborted                 /usr/lib/jvm/temurin-8-jdk-amd64/bin/java -server -Xmx5739m -Djava.io.tmpdir=/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000005/tmp '-Dspark.driver.port=35073' '-Dspark.ui.port=0' '-Dspark.rpc.message.maxSize=512' -Dspark.yarn.app.container.log.dir=/var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000005 -XX:OnOutOfMemoryError='kill %p' org.apache.spark.executor.YarnCoarseGrainedExecutorBackend --driver-url spark://CoarseGrainedScheduler@hw2-m.c.csee4121-339916.internal:35073 --executor-id 4 --hostname hw2-w-1.c.csee4121-339916.internal --cores 2 --app-id application_1650379967059_0008 --resourceProfileId 0 --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000005/__app__.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000005/com.databricks_spark-xml_2.12-0.14.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000005/commons-io_commons-io-2.8.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000005/org.glassfish.jaxb_txw2-2.3.4.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000005/org.apache.ws.xmlschema_xmlschema-core-2.2.5.jar > /var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000005/stdout 2> /var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000005/stderr\n",
      "Last 4096 bytes of stderr :\n",
      "\n",
      "\n",
      "[2022-04-20 00:09:38.258]Container exited with a non-zero exit code 134. Error file: prelaunch.err.\n",
      "Last 4096 bytes of prelaunch.err :\n",
      "/bin/bash: line 1: 19630 Aborted                 /usr/lib/jvm/temurin-8-jdk-amd64/bin/java -server -Xmx5739m -Djava.io.tmpdir=/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000005/tmp '-Dspark.driver.port=35073' '-Dspark.ui.port=0' '-Dspark.rpc.message.maxSize=512' -Dspark.yarn.app.container.log.dir=/var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000005 -XX:OnOutOfMemoryError='kill %p' org.apache.spark.executor.YarnCoarseGrainedExecutorBackend --driver-url spark://CoarseGrainedScheduler@hw2-m.c.csee4121-339916.internal:35073 --executor-id 4 --hostname hw2-w-1.c.csee4121-339916.internal --cores 2 --app-id application_1650379967059_0008 --resourceProfileId 0 --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000005/__app__.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000005/com.databricks_spark-xml_2.12-0.14.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000005/commons-io_commons-io-2.8.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000005/org.glassfish.jaxb_txw2-2.3.4.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000005/org.apache.ws.xmlschema_xmlschema-core-2.2.5.jar > /var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000005/stdout 2> /var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000005/stderr\n",
      "Last 4096 bytes of stderr :\n",
      "\n",
      "\n",
      ".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/04/20 00:09:56 WARN org.apache.spark.deploy.yarn.YarnAllocator: Container from a bad node: container_1650379967059_0008_01_000007 on host: hw2-w-1.c.csee4121-339916.internal. Exit status: 134. Diagnostics: [2022-04-20 00:09:55.906]Exception from container-launch.\n",
      "Container id: container_1650379967059_0008_01_000007\n",
      "Exit code: 134\n",
      "\n",
      "[2022-04-20 00:09:55.909]Container exited with a non-zero exit code 134. Error file: prelaunch.err.\n",
      "Last 4096 bytes of prelaunch.err :\n",
      "/bin/bash: line 1: 19895 Aborted                 /usr/lib/jvm/temurin-8-jdk-amd64/bin/java -server -Xmx5739m -Djava.io.tmpdir=/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000007/tmp '-Dspark.driver.port=35073' '-Dspark.ui.port=0' '-Dspark.rpc.message.maxSize=512' -Dspark.yarn.app.container.log.dir=/var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000007 -XX:OnOutOfMemoryError='kill %p' org.apache.spark.executor.YarnCoarseGrainedExecutorBackend --driver-url spark://CoarseGrainedScheduler@hw2-m.c.csee4121-339916.internal:35073 --executor-id 6 --hostname hw2-w-1.c.csee4121-339916.internal --cores 2 --app-id application_1650379967059_0008 --resourceProfileId 0 --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000007/__app__.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000007/com.databricks_spark-xml_2.12-0.14.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000007/commons-io_commons-io-2.8.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000007/org.glassfish.jaxb_txw2-2.3.4.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000007/org.apache.ws.xmlschema_xmlschema-core-2.2.5.jar > /var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000007/stdout 2> /var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000007/stderr\n",
      "Last 4096 bytes of stderr :\n",
      "\n",
      "\n",
      "[2022-04-20 00:09:55.909]Container exited with a non-zero exit code 134. Error file: prelaunch.err.\n",
      "Last 4096 bytes of prelaunch.err :\n",
      "/bin/bash: line 1: 19895 Aborted                 /usr/lib/jvm/temurin-8-jdk-amd64/bin/java -server -Xmx5739m -Djava.io.tmpdir=/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000007/tmp '-Dspark.driver.port=35073' '-Dspark.ui.port=0' '-Dspark.rpc.message.maxSize=512' -Dspark.yarn.app.container.log.dir=/var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000007 -XX:OnOutOfMemoryError='kill %p' org.apache.spark.executor.YarnCoarseGrainedExecutorBackend --driver-url spark://CoarseGrainedScheduler@hw2-m.c.csee4121-339916.internal:35073 --executor-id 6 --hostname hw2-w-1.c.csee4121-339916.internal --cores 2 --app-id application_1650379967059_0008 --resourceProfileId 0 --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000007/__app__.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000007/com.databricks_spark-xml_2.12-0.14.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000007/commons-io_commons-io-2.8.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000007/org.glassfish.jaxb_txw2-2.3.4.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000007/org.apache.ws.xmlschema_xmlschema-core-2.2.5.jar > /var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000007/stdout 2> /var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000007/stderr\n",
      "Last 4096 bytes of stderr :\n",
      "\n",
      "\n",
      ".\n",
      "22/04/20 00:09:56 WARN org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 6 for reason Container from a bad node: container_1650379967059_0008_01_000007 on host: hw2-w-1.c.csee4121-339916.internal. Exit status: 134. Diagnostics: [2022-04-20 00:09:55.906]Exception from container-launch.\n",
      "Container id: container_1650379967059_0008_01_000007\n",
      "Exit code: 134\n",
      "\n",
      "[2022-04-20 00:09:55.909]Container exited with a non-zero exit code 134. Error file: prelaunch.err.\n",
      "Last 4096 bytes of prelaunch.err :\n",
      "/bin/bash: line 1: 19895 Aborted                 /usr/lib/jvm/temurin-8-jdk-amd64/bin/java -server -Xmx5739m -Djava.io.tmpdir=/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000007/tmp '-Dspark.driver.port=35073' '-Dspark.ui.port=0' '-Dspark.rpc.message.maxSize=512' -Dspark.yarn.app.container.log.dir=/var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000007 -XX:OnOutOfMemoryError='kill %p' org.apache.spark.executor.YarnCoarseGrainedExecutorBackend --driver-url spark://CoarseGrainedScheduler@hw2-m.c.csee4121-339916.internal:35073 --executor-id 6 --hostname hw2-w-1.c.csee4121-339916.internal --cores 2 --app-id application_1650379967059_0008 --resourceProfileId 0 --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000007/__app__.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000007/com.databricks_spark-xml_2.12-0.14.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000007/commons-io_commons-io-2.8.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000007/org.glassfish.jaxb_txw2-2.3.4.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000007/org.apache.ws.xmlschema_xmlschema-core-2.2.5.jar > /var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000007/stdout 2> /var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000007/stderr\n",
      "Last 4096 bytes of stderr :\n",
      "\n",
      "\n",
      "[2022-04-20 00:09:55.909]Container exited with a non-zero exit code 134. Error file: prelaunch.err.\n",
      "Last 4096 bytes of prelaunch.err :\n",
      "/bin/bash: line 1: 19895 Aborted                 /usr/lib/jvm/temurin-8-jdk-amd64/bin/java -server -Xmx5739m -Djava.io.tmpdir=/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000007/tmp '-Dspark.driver.port=35073' '-Dspark.ui.port=0' '-Dspark.rpc.message.maxSize=512' -Dspark.yarn.app.container.log.dir=/var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000007 -XX:OnOutOfMemoryError='kill %p' org.apache.spark.executor.YarnCoarseGrainedExecutorBackend --driver-url spark://CoarseGrainedScheduler@hw2-m.c.csee4121-339916.internal:35073 --executor-id 6 --hostname hw2-w-1.c.csee4121-339916.internal --cores 2 --app-id application_1650379967059_0008 --resourceProfileId 0 --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000007/__app__.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000007/com.databricks_spark-xml_2.12-0.14.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000007/commons-io_commons-io-2.8.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000007/org.glassfish.jaxb_txw2-2.3.4.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000007/org.apache.ws.xmlschema_xmlschema-core-2.2.5.jar > /var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000007/stdout 2> /var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000007/stderr\n",
      "Last 4096 bytes of stderr :\n",
      "\n",
      "\n",
      ".\n",
      "22/04/20 00:09:56 ERROR org.apache.spark.scheduler.cluster.YarnScheduler: Lost executor 6 on hw2-w-1.c.csee4121-339916.internal: Container from a bad node: container_1650379967059_0008_01_000007 on host: hw2-w-1.c.csee4121-339916.internal. Exit status: 134. Diagnostics: [2022-04-20 00:09:55.906]Exception from container-launch.\n",
      "Container id: container_1650379967059_0008_01_000007\n",
      "Exit code: 134\n",
      "\n",
      "[2022-04-20 00:09:55.909]Container exited with a non-zero exit code 134. Error file: prelaunch.err.\n",
      "Last 4096 bytes of prelaunch.err :\n",
      "/bin/bash: line 1: 19895 Aborted                 /usr/lib/jvm/temurin-8-jdk-amd64/bin/java -server -Xmx5739m -Djava.io.tmpdir=/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000007/tmp '-Dspark.driver.port=35073' '-Dspark.ui.port=0' '-Dspark.rpc.message.maxSize=512' -Dspark.yarn.app.container.log.dir=/var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000007 -XX:OnOutOfMemoryError='kill %p' org.apache.spark.executor.YarnCoarseGrainedExecutorBackend --driver-url spark://CoarseGrainedScheduler@hw2-m.c.csee4121-339916.internal:35073 --executor-id 6 --hostname hw2-w-1.c.csee4121-339916.internal --cores 2 --app-id application_1650379967059_0008 --resourceProfileId 0 --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000007/__app__.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000007/com.databricks_spark-xml_2.12-0.14.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000007/commons-io_commons-io-2.8.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000007/org.glassfish.jaxb_txw2-2.3.4.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000007/org.apache.ws.xmlschema_xmlschema-core-2.2.5.jar > /var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000007/stdout 2> /var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000007/stderr\n",
      "Last 4096 bytes of stderr :\n",
      "\n",
      "\n",
      "[2022-04-20 00:09:55.909]Container exited with a non-zero exit code 134. Error file: prelaunch.err.\n",
      "Last 4096 bytes of prelaunch.err :\n",
      "/bin/bash: line 1: 19895 Aborted                 /usr/lib/jvm/temurin-8-jdk-amd64/bin/java -server -Xmx5739m -Djava.io.tmpdir=/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000007/tmp '-Dspark.driver.port=35073' '-Dspark.ui.port=0' '-Dspark.rpc.message.maxSize=512' -Dspark.yarn.app.container.log.dir=/var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000007 -XX:OnOutOfMemoryError='kill %p' org.apache.spark.executor.YarnCoarseGrainedExecutorBackend --driver-url spark://CoarseGrainedScheduler@hw2-m.c.csee4121-339916.internal:35073 --executor-id 6 --hostname hw2-w-1.c.csee4121-339916.internal --cores 2 --app-id application_1650379967059_0008 --resourceProfileId 0 --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000007/__app__.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000007/com.databricks_spark-xml_2.12-0.14.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000007/commons-io_commons-io-2.8.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000007/org.glassfish.jaxb_txw2-2.3.4.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650379967059_0008/container_1650379967059_0008_01_000007/org.apache.ws.xmlschema_xmlschema-core-2.2.5.jar > /var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000007/stdout 2> /var/log/hadoop-yarn/userlogs/application_1650379967059_0008/container_1650379967059_0008_01_000007/stderr\n",
      "Last 4096 bytes of stderr :\n",
      "\n",
      "\n",
      ".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    newdf = df.join(newdf, df._c0 == newdf.article, 'inner')\n",
    "    newdf = newdf.groupBy(['_c1']).sum('contribution').rdd.map(lambda x: (x[0], 0.15 + 0.85 * x[1])).toDF(['article', 'rank'])\n",
    "    newdf = df_count.join(newdf, df._c0 == newdf.article, 'left')\n",
    "    newdf = newdf.na.fill(0.15)\n",
    "    newdf = newdf.rdd.map(lambda x:(x[0], x[1], x[3], x[3]/x[1])).toDF(['article', 'count', 'rank', 'contribution'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d63e094d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 264:========================>                                (3 + 4) / 7]\r",
      "\r",
      "[Stage 264:========================================>                (5 + 2) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----+\n",
      "|          article|rank|\n",
      "+-----------------+----+\n",
      "|   1984/new speak|0.15|\n",
      "|              509|0.15|\n",
      "|           1e15 m|0.15|\n",
      "|          1 e-7 s|0.15|\n",
      "|           1e18 m|0.15|\n",
      "|         1 e17 kg|0.15|\n",
      "|2010: odyssey two|0.15|\n",
      "|           1 e9 s|0.15|\n",
      "|             2021|0.15|\n",
      "|   100 picometres|0.15|\n",
      "|             2024|0.15|\n",
      "|          1 e-2 s|0.15|\n",
      "|             2032|0.15|\n",
      "|              134|0.15|\n",
      "|         2150s bc|0.15|\n",
      "|    10 nanometres|0.15|\n",
      "|          1607 bc|0.15|\n",
      "|          1609 bc|0.15|\n",
      "|          1618 bc|0.15|\n",
      "|          1679 bc|0.15|\n",
      "+-----------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "newdf = newdf.select('article', 'rank').orderBy('rank')\n",
    "newdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2945d12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "newdf.repartition(10).write.option(\"delimiter\", \"\\t\").csv('p1t3_small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3256ab7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf.limit(5).toPandas().to_csv('/home/jz3313/hw2/p1t3.csv', sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
