{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b90d7e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.databricks:spark-xml_2.12:0.14.0 pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1b381fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/usr/lib/spark/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      "com.databricks#spark-xml_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-4187b8f0-a486-4de7-85c3-6fdd5c3e2f9a;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.databricks#spark-xml_2.12;0.14.0 in central\n",
      "\tfound commons-io#commons-io;2.8.0 in central\n",
      "\tfound org.glassfish.jaxb#txw2;2.3.4 in central\n",
      "\tfound org.apache.ws.xmlschema#xmlschema-core;2.2.5 in central\n",
      ":: resolution report :: resolve 278ms :: artifacts dl 7ms\n",
      "\t:: modules in use:\n",
      "\tcom.databricks#spark-xml_2.12;0.14.0 from central in [default]\n",
      "\tcommons-io#commons-io;2.8.0 from central in [default]\n",
      "\torg.apache.ws.xmlschema#xmlschema-core;2.2.5 from central in [default]\n",
      "\torg.glassfish.jaxb#txw2;2.3.4 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   4   |   0   |   0   |   0   ||   4   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-4187b8f0-a486-4de7-85c3-6fdd5c3e2f9a\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 4 already retrieved (0kB/8ms)\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/04/22 21:43:19 INFO org.apache.spark.SparkEnv: Registering MapOutputTracker\n",
      "22/04/22 21:43:19 INFO org.apache.spark.SparkEnv: Registering BlockManagerMaster\n",
      "22/04/22 21:43:19 INFO org.apache.spark.SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "22/04/22 21:43:19 INFO org.apache.spark.SparkEnv: Registering OutputCommitCoordinator\n",
      "22/04/22 21:43:21 WARN org.apache.spark.deploy.yarn.Client: Same path resource file:///root/.ivy2/jars/com.databricks_spark-xml_2.12-0.14.0.jar added multiple times to distributed cache.\n",
      "22/04/22 21:43:21 WARN org.apache.spark.deploy.yarn.Client: Same path resource file:///root/.ivy2/jars/commons-io_commons-io-2.8.0.jar added multiple times to distributed cache.\n",
      "22/04/22 21:43:21 WARN org.apache.spark.deploy.yarn.Client: Same path resource file:///root/.ivy2/jars/org.glassfish.jaxb_txw2-2.3.4.jar added multiple times to distributed cache.\n",
      "22/04/22 21:43:21 WARN org.apache.spark.deploy.yarn.Client: Same path resource file:///root/.ivy2/jars/org.apache.ws.xmlschema_xmlschema-core-2.2.5.jar added multiple times to distributed cache.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "df = spark.read.option(\"delimiter\", \"\\t\").csv('hdfs://hw2-m/user/root/p1t2_small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "697aadc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4413753"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.filter(\"_c1 is not null\")\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "353f29f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "\n",
    "df_count = df.groupBy(\"_c0\").count()\n",
    "newdf = df_count.withColumn(\"rank\", lit(1))\n",
    "newdf = newdf.rdd.map(lambda x: (x[0], x[1], x[2], x[2]/x[1])).toDF(['article', 'count', 'rank', 'contribution'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aaef07b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/04/22 21:43:52 WARN org.apache.spark.deploy.yarn.YarnAllocator: Container from a bad node: container_1650653302475_0004_01_000004 on host: hw2-w-0.c.csee4121-339916.internal. Exit status: 134. Diagnostics: [2022-04-22 21:43:52.769]Exception from container-launch.\n",
      "Container id: container_1650653302475_0004_01_000004\n",
      "Exit code: 134\n",
      "\n",
      "[2022-04-22 21:43:52.772]Container exited with a non-zero exit code 134. Error file: prelaunch.err.\n",
      "Last 4096 bytes of prelaunch.err :\n",
      "/bin/bash: line 1:  4670 Aborted                 /usr/lib/jvm/temurin-8-jdk-amd64/bin/java -server -Xmx5739m -Djava.io.tmpdir=/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000004/tmp '-Dspark.driver.port=44927' '-Dspark.ui.port=0' '-Dspark.rpc.message.maxSize=512' -Dspark.yarn.app.container.log.dir=/var/log/hadoop-yarn/userlogs/application_1650653302475_0004/container_1650653302475_0004_01_000004 -XX:OnOutOfMemoryError='kill %p' org.apache.spark.executor.YarnCoarseGrainedExecutorBackend --driver-url spark://CoarseGrainedScheduler@hw2-m.c.csee4121-339916.internal:44927 --executor-id 3 --hostname hw2-w-0.c.csee4121-339916.internal --cores 2 --app-id application_1650653302475_0004 --resourceProfileId 0 --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000004/__app__.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000004/com.databricks_spark-xml_2.12-0.14.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000004/commons-io_commons-io-2.8.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000004/org.glassfish.jaxb_txw2-2.3.4.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000004/org.apache.ws.xmlschema_xmlschema-core-2.2.5.jar > /var/log/hadoop-yarn/userlogs/application_1650653302475_0004/container_1650653302475_0004_01_000004/stdout 2> /var/log/hadoop-yarn/userlogs/application_1650653302475_0004/container_1650653302475_0004_01_000004/stderr\n",
      "Last 4096 bytes of stderr :\n",
      "\n",
      "\n",
      "[2022-04-22 21:43:52.772]Container exited with a non-zero exit code 134. Error file: prelaunch.err.\n",
      "Last 4096 bytes of prelaunch.err :\n",
      "/bin/bash: line 1:  4670 Aborted                 /usr/lib/jvm/temurin-8-jdk-amd64/bin/java -server -Xmx5739m -Djava.io.tmpdir=/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000004/tmp '-Dspark.driver.port=44927' '-Dspark.ui.port=0' '-Dspark.rpc.message.maxSize=512' -Dspark.yarn.app.container.log.dir=/var/log/hadoop-yarn/userlogs/application_1650653302475_0004/container_1650653302475_0004_01_000004 -XX:OnOutOfMemoryError='kill %p' org.apache.spark.executor.YarnCoarseGrainedExecutorBackend --driver-url spark://CoarseGrainedScheduler@hw2-m.c.csee4121-339916.internal:44927 --executor-id 3 --hostname hw2-w-0.c.csee4121-339916.internal --cores 2 --app-id application_1650653302475_0004 --resourceProfileId 0 --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000004/__app__.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000004/com.databricks_spark-xml_2.12-0.14.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000004/commons-io_commons-io-2.8.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000004/org.glassfish.jaxb_txw2-2.3.4.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000004/org.apache.ws.xmlschema_xmlschema-core-2.2.5.jar > /var/log/hadoop-yarn/userlogs/application_1650653302475_0004/container_1650653302475_0004_01_000004/stdout 2> /var/log/hadoop-yarn/userlogs/application_1650653302475_0004/container_1650653302475_0004_01_000004/stderr\n",
      "Last 4096 bytes of stderr :\n",
      "\n",
      "\n",
      ".\n",
      "22/04/22 21:43:52 WARN org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 3 for reason Container from a bad node: container_1650653302475_0004_01_000004 on host: hw2-w-0.c.csee4121-339916.internal. Exit status: 134. Diagnostics: [2022-04-22 21:43:52.769]Exception from container-launch.\n",
      "Container id: container_1650653302475_0004_01_000004\n",
      "Exit code: 134\n",
      "\n",
      "[2022-04-22 21:43:52.772]Container exited with a non-zero exit code 134. Error file: prelaunch.err.\n",
      "Last 4096 bytes of prelaunch.err :\n",
      "/bin/bash: line 1:  4670 Aborted                 /usr/lib/jvm/temurin-8-jdk-amd64/bin/java -server -Xmx5739m -Djava.io.tmpdir=/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000004/tmp '-Dspark.driver.port=44927' '-Dspark.ui.port=0' '-Dspark.rpc.message.maxSize=512' -Dspark.yarn.app.container.log.dir=/var/log/hadoop-yarn/userlogs/application_1650653302475_0004/container_1650653302475_0004_01_000004 -XX:OnOutOfMemoryError='kill %p' org.apache.spark.executor.YarnCoarseGrainedExecutorBackend --driver-url spark://CoarseGrainedScheduler@hw2-m.c.csee4121-339916.internal:44927 --executor-id 3 --hostname hw2-w-0.c.csee4121-339916.internal --cores 2 --app-id application_1650653302475_0004 --resourceProfileId 0 --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000004/__app__.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000004/com.databricks_spark-xml_2.12-0.14.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000004/commons-io_commons-io-2.8.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000004/org.glassfish.jaxb_txw2-2.3.4.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000004/org.apache.ws.xmlschema_xmlschema-core-2.2.5.jar > /var/log/hadoop-yarn/userlogs/application_1650653302475_0004/container_1650653302475_0004_01_000004/stdout 2> /var/log/hadoop-yarn/userlogs/application_1650653302475_0004/container_1650653302475_0004_01_000004/stderr\n",
      "Last 4096 bytes of stderr :\n",
      "\n",
      "\n",
      "[2022-04-22 21:43:52.772]Container exited with a non-zero exit code 134. Error file: prelaunch.err.\n",
      "Last 4096 bytes of prelaunch.err :\n",
      "/bin/bash: line 1:  4670 Aborted                 /usr/lib/jvm/temurin-8-jdk-amd64/bin/java -server -Xmx5739m -Djava.io.tmpdir=/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000004/tmp '-Dspark.driver.port=44927' '-Dspark.ui.port=0' '-Dspark.rpc.message.maxSize=512' -Dspark.yarn.app.container.log.dir=/var/log/hadoop-yarn/userlogs/application_1650653302475_0004/container_1650653302475_0004_01_000004 -XX:OnOutOfMemoryError='kill %p' org.apache.spark.executor.YarnCoarseGrainedExecutorBackend --driver-url spark://CoarseGrainedScheduler@hw2-m.c.csee4121-339916.internal:44927 --executor-id 3 --hostname hw2-w-0.c.csee4121-339916.internal --cores 2 --app-id application_1650653302475_0004 --resourceProfileId 0 --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000004/__app__.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000004/com.databricks_spark-xml_2.12-0.14.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000004/commons-io_commons-io-2.8.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000004/org.glassfish.jaxb_txw2-2.3.4.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000004/org.apache.ws.xmlschema_xmlschema-core-2.2.5.jar > /var/log/hadoop-yarn/userlogs/application_1650653302475_0004/container_1650653302475_0004_01_000004/stdout 2> /var/log/hadoop-yarn/userlogs/application_1650653302475_0004/container_1650653302475_0004_01_000004/stderr\n",
      "Last 4096 bytes of stderr :\n",
      "\n",
      "\n",
      ".\n",
      "22/04/22 21:43:52 ERROR org.apache.spark.scheduler.cluster.YarnScheduler: Lost executor 3 on hw2-w-0.c.csee4121-339916.internal: Container from a bad node: container_1650653302475_0004_01_000004 on host: hw2-w-0.c.csee4121-339916.internal. Exit status: 134. Diagnostics: [2022-04-22 21:43:52.769]Exception from container-launch.\n",
      "Container id: container_1650653302475_0004_01_000004\n",
      "Exit code: 134\n",
      "\n",
      "[2022-04-22 21:43:52.772]Container exited with a non-zero exit code 134. Error file: prelaunch.err.\n",
      "Last 4096 bytes of prelaunch.err :\n",
      "/bin/bash: line 1:  4670 Aborted                 /usr/lib/jvm/temurin-8-jdk-amd64/bin/java -server -Xmx5739m -Djava.io.tmpdir=/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000004/tmp '-Dspark.driver.port=44927' '-Dspark.ui.port=0' '-Dspark.rpc.message.maxSize=512' -Dspark.yarn.app.container.log.dir=/var/log/hadoop-yarn/userlogs/application_1650653302475_0004/container_1650653302475_0004_01_000004 -XX:OnOutOfMemoryError='kill %p' org.apache.spark.executor.YarnCoarseGrainedExecutorBackend --driver-url spark://CoarseGrainedScheduler@hw2-m.c.csee4121-339916.internal:44927 --executor-id 3 --hostname hw2-w-0.c.csee4121-339916.internal --cores 2 --app-id application_1650653302475_0004 --resourceProfileId 0 --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000004/__app__.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000004/com.databricks_spark-xml_2.12-0.14.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000004/commons-io_commons-io-2.8.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000004/org.glassfish.jaxb_txw2-2.3.4.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000004/org.apache.ws.xmlschema_xmlschema-core-2.2.5.jar > /var/log/hadoop-yarn/userlogs/application_1650653302475_0004/container_1650653302475_0004_01_000004/stdout 2> /var/log/hadoop-yarn/userlogs/application_1650653302475_0004/container_1650653302475_0004_01_000004/stderr\n",
      "Last 4096 bytes of stderr :\n",
      "\n",
      "\n",
      "[2022-04-22 21:43:52.772]Container exited with a non-zero exit code 134. Error file: prelaunch.err.\n",
      "Last 4096 bytes of prelaunch.err :\n",
      "/bin/bash: line 1:  4670 Aborted                 /usr/lib/jvm/temurin-8-jdk-amd64/bin/java -server -Xmx5739m -Djava.io.tmpdir=/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000004/tmp '-Dspark.driver.port=44927' '-Dspark.ui.port=0' '-Dspark.rpc.message.maxSize=512' -Dspark.yarn.app.container.log.dir=/var/log/hadoop-yarn/userlogs/application_1650653302475_0004/container_1650653302475_0004_01_000004 -XX:OnOutOfMemoryError='kill %p' org.apache.spark.executor.YarnCoarseGrainedExecutorBackend --driver-url spark://CoarseGrainedScheduler@hw2-m.c.csee4121-339916.internal:44927 --executor-id 3 --hostname hw2-w-0.c.csee4121-339916.internal --cores 2 --app-id application_1650653302475_0004 --resourceProfileId 0 --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000004/__app__.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000004/com.databricks_spark-xml_2.12-0.14.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000004/commons-io_commons-io-2.8.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000004/org.glassfish.jaxb_txw2-2.3.4.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000004/org.apache.ws.xmlschema_xmlschema-core-2.2.5.jar > /var/log/hadoop-yarn/userlogs/application_1650653302475_0004/container_1650653302475_0004_01_000004/stdout 2> /var/log/hadoop-yarn/userlogs/application_1650653302475_0004/container_1650653302475_0004_01_000004/stderr\n",
      "Last 4096 bytes of stderr :\n",
      "\n",
      "\n",
      ".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 8:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+----+--------------------+\n",
      "|             article|count|rank|        contribution|\n",
      "+--------------------+-----+----+--------------------+\n",
      "|hypothetical type...|  406|   1|0.002463054187192...|\n",
      "|guantanamo bay na...|  160|   1|             0.00625|\n",
      "|     jerzy grotowski|   56|   1|0.017857142857142856|\n",
      "|georg wilhelm fri...|  527|   1|0.001897533206831...|\n",
      "|johns hopkins uni...|  391|   1|0.002557544757033...|\n",
      "|johann heinrich a...|   24|   1|0.041666666666666664|\n",
      "|      greek language|  315|   1|0.003174603174603...|\n",
      "|geography of moldova|  148|   1|0.006756756756756757|\n",
      "|                 fog|  159|   1|0.006289308176100629|\n",
      "|            guernsey|  311|   1|0.003215434083601286|\n",
      "|       gary, indiana|  230|   1|0.004347826086956522|\n",
      "|       georges perec|  111|   1|0.009009009009009009|\n",
      "|      frederick abel|   69|   1|0.014492753623188406|\n",
      "|       james madison|  296|   1|0.003378378378378...|\n",
      "|             hydrate|   53|   1|0.018867924528301886|\n",
      "|james madison uni...|   94|   1|0.010638297872340425|\n",
      "|indo-iranian lang...|  153|   1|0.006535947712418301|\n",
      "| green mountain boys|  106|   1|0.009433962264150943|\n",
      "|            john ray|   81|   1|0.012345679012345678|\n",
      "|         java applet|   94|   1|0.010638297872340425|\n",
      "+--------------------+-----+----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "newdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beeb8590",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/04/22 21:44:09 WARN org.apache.spark.deploy.yarn.YarnAllocator: Container from a bad node: container_1650653302475_0004_01_000002 on host: hw2-w-0.c.csee4121-339916.internal. Exit status: 134. Diagnostics: [2022-04-22 21:44:09.330]Exception from container-launch.\n",
      "Container id: container_1650653302475_0004_01_000002\n",
      "Exit code: 134\n",
      "\n",
      "[2022-04-22 21:44:09.331]Container exited with a non-zero exit code 134. Error file: prelaunch.err.\n",
      "Last 4096 bytes of prelaunch.err :\n",
      "/bin/bash: line 1:  4616 Aborted                 /usr/lib/jvm/temurin-8-jdk-amd64/bin/java -server -Xmx5739m -Djava.io.tmpdir=/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000002/tmp '-Dspark.driver.port=44927' '-Dspark.ui.port=0' '-Dspark.rpc.message.maxSize=512' -Dspark.yarn.app.container.log.dir=/var/log/hadoop-yarn/userlogs/application_1650653302475_0004/container_1650653302475_0004_01_000002 -XX:OnOutOfMemoryError='kill %p' org.apache.spark.executor.YarnCoarseGrainedExecutorBackend --driver-url spark://CoarseGrainedScheduler@hw2-m.c.csee4121-339916.internal:44927 --executor-id 2 --hostname hw2-w-0.c.csee4121-339916.internal --cores 2 --app-id application_1650653302475_0004 --resourceProfileId 0 --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000002/__app__.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000002/com.databricks_spark-xml_2.12-0.14.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000002/commons-io_commons-io-2.8.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000002/org.glassfish.jaxb_txw2-2.3.4.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000002/org.apache.ws.xmlschema_xmlschema-core-2.2.5.jar > /var/log/hadoop-yarn/userlogs/application_1650653302475_0004/container_1650653302475_0004_01_000002/stdout 2> /var/log/hadoop-yarn/userlogs/application_1650653302475_0004/container_1650653302475_0004_01_000002/stderr\n",
      "Last 4096 bytes of stderr :\n",
      "\n",
      "\n",
      "[2022-04-22 21:44:09.332]Container exited with a non-zero exit code 134. Error file: prelaunch.err.\n",
      "Last 4096 bytes of prelaunch.err :\n",
      "/bin/bash: line 1:  4616 Aborted                 /usr/lib/jvm/temurin-8-jdk-amd64/bin/java -server -Xmx5739m -Djava.io.tmpdir=/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000002/tmp '-Dspark.driver.port=44927' '-Dspark.ui.port=0' '-Dspark.rpc.message.maxSize=512' -Dspark.yarn.app.container.log.dir=/var/log/hadoop-yarn/userlogs/application_1650653302475_0004/container_1650653302475_0004_01_000002 -XX:OnOutOfMemoryError='kill %p' org.apache.spark.executor.YarnCoarseGrainedExecutorBackend --driver-url spark://CoarseGrainedScheduler@hw2-m.c.csee4121-339916.internal:44927 --executor-id 2 --hostname hw2-w-0.c.csee4121-339916.internal --cores 2 --app-id application_1650653302475_0004 --resourceProfileId 0 --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000002/__app__.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000002/com.databricks_spark-xml_2.12-0.14.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000002/commons-io_commons-io-2.8.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000002/org.glassfish.jaxb_txw2-2.3.4.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000002/org.apache.ws.xmlschema_xmlschema-core-2.2.5.jar > /var/log/hadoop-yarn/userlogs/application_1650653302475_0004/container_1650653302475_0004_01_000002/stdout 2> /var/log/hadoop-yarn/userlogs/application_1650653302475_0004/container_1650653302475_0004_01_000002/stderr\n",
      "Last 4096 bytes of stderr :\n",
      "\n",
      "\n",
      ".\n",
      "22/04/22 21:44:09 WARN org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 2 for reason Container from a bad node: container_1650653302475_0004_01_000002 on host: hw2-w-0.c.csee4121-339916.internal. Exit status: 134. Diagnostics: [2022-04-22 21:44:09.330]Exception from container-launch.\n",
      "Container id: container_1650653302475_0004_01_000002\n",
      "Exit code: 134\n",
      "\n",
      "[2022-04-22 21:44:09.331]Container exited with a non-zero exit code 134. Error file: prelaunch.err.\n",
      "Last 4096 bytes of prelaunch.err :\n",
      "/bin/bash: line 1:  4616 Aborted                 /usr/lib/jvm/temurin-8-jdk-amd64/bin/java -server -Xmx5739m -Djava.io.tmpdir=/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000002/tmp '-Dspark.driver.port=44927' '-Dspark.ui.port=0' '-Dspark.rpc.message.maxSize=512' -Dspark.yarn.app.container.log.dir=/var/log/hadoop-yarn/userlogs/application_1650653302475_0004/container_1650653302475_0004_01_000002 -XX:OnOutOfMemoryError='kill %p' org.apache.spark.executor.YarnCoarseGrainedExecutorBackend --driver-url spark://CoarseGrainedScheduler@hw2-m.c.csee4121-339916.internal:44927 --executor-id 2 --hostname hw2-w-0.c.csee4121-339916.internal --cores 2 --app-id application_1650653302475_0004 --resourceProfileId 0 --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000002/__app__.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000002/com.databricks_spark-xml_2.12-0.14.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000002/commons-io_commons-io-2.8.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000002/org.glassfish.jaxb_txw2-2.3.4.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000002/org.apache.ws.xmlschema_xmlschema-core-2.2.5.jar > /var/log/hadoop-yarn/userlogs/application_1650653302475_0004/container_1650653302475_0004_01_000002/stdout 2> /var/log/hadoop-yarn/userlogs/application_1650653302475_0004/container_1650653302475_0004_01_000002/stderr\n",
      "Last 4096 bytes of stderr :\n",
      "\n",
      "\n",
      "[2022-04-22 21:44:09.332]Container exited with a non-zero exit code 134. Error file: prelaunch.err.\n",
      "Last 4096 bytes of prelaunch.err :\n",
      "/bin/bash: line 1:  4616 Aborted                 /usr/lib/jvm/temurin-8-jdk-amd64/bin/java -server -Xmx5739m -Djava.io.tmpdir=/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000002/tmp '-Dspark.driver.port=44927' '-Dspark.ui.port=0' '-Dspark.rpc.message.maxSize=512' -Dspark.yarn.app.container.log.dir=/var/log/hadoop-yarn/userlogs/application_1650653302475_0004/container_1650653302475_0004_01_000002 -XX:OnOutOfMemoryError='kill %p' org.apache.spark.executor.YarnCoarseGrainedExecutorBackend --driver-url spark://CoarseGrainedScheduler@hw2-m.c.csee4121-339916.internal:44927 --executor-id 2 --hostname hw2-w-0.c.csee4121-339916.internal --cores 2 --app-id application_1650653302475_0004 --resourceProfileId 0 --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000002/__app__.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000002/com.databricks_spark-xml_2.12-0.14.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000002/commons-io_commons-io-2.8.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000002/org.glassfish.jaxb_txw2-2.3.4.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000002/org.apache.ws.xmlschema_xmlschema-core-2.2.5.jar > /var/log/hadoop-yarn/userlogs/application_1650653302475_0004/container_1650653302475_0004_01_000002/stdout 2> /var/log/hadoop-yarn/userlogs/application_1650653302475_0004/container_1650653302475_0004_01_000002/stderr\n",
      "Last 4096 bytes of stderr :\n",
      "\n",
      "\n",
      ".\n",
      "22/04/22 21:44:09 ERROR org.apache.spark.scheduler.cluster.YarnScheduler: Lost executor 2 on hw2-w-0.c.csee4121-339916.internal: Container from a bad node: container_1650653302475_0004_01_000002 on host: hw2-w-0.c.csee4121-339916.internal. Exit status: 134. Diagnostics: [2022-04-22 21:44:09.330]Exception from container-launch.\n",
      "Container id: container_1650653302475_0004_01_000002\n",
      "Exit code: 134\n",
      "\n",
      "[2022-04-22 21:44:09.331]Container exited with a non-zero exit code 134. Error file: prelaunch.err.\n",
      "Last 4096 bytes of prelaunch.err :\n",
      "/bin/bash: line 1:  4616 Aborted                 /usr/lib/jvm/temurin-8-jdk-amd64/bin/java -server -Xmx5739m -Djava.io.tmpdir=/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000002/tmp '-Dspark.driver.port=44927' '-Dspark.ui.port=0' '-Dspark.rpc.message.maxSize=512' -Dspark.yarn.app.container.log.dir=/var/log/hadoop-yarn/userlogs/application_1650653302475_0004/container_1650653302475_0004_01_000002 -XX:OnOutOfMemoryError='kill %p' org.apache.spark.executor.YarnCoarseGrainedExecutorBackend --driver-url spark://CoarseGrainedScheduler@hw2-m.c.csee4121-339916.internal:44927 --executor-id 2 --hostname hw2-w-0.c.csee4121-339916.internal --cores 2 --app-id application_1650653302475_0004 --resourceProfileId 0 --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000002/__app__.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000002/com.databricks_spark-xml_2.12-0.14.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000002/commons-io_commons-io-2.8.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000002/org.glassfish.jaxb_txw2-2.3.4.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000002/org.apache.ws.xmlschema_xmlschema-core-2.2.5.jar > /var/log/hadoop-yarn/userlogs/application_1650653302475_0004/container_1650653302475_0004_01_000002/stdout 2> /var/log/hadoop-yarn/userlogs/application_1650653302475_0004/container_1650653302475_0004_01_000002/stderr\n",
      "Last 4096 bytes of stderr :\n",
      "\n",
      "\n",
      "[2022-04-22 21:44:09.332]Container exited with a non-zero exit code 134. Error file: prelaunch.err.\n",
      "Last 4096 bytes of prelaunch.err :\n",
      "/bin/bash: line 1:  4616 Aborted                 /usr/lib/jvm/temurin-8-jdk-amd64/bin/java -server -Xmx5739m -Djava.io.tmpdir=/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000002/tmp '-Dspark.driver.port=44927' '-Dspark.ui.port=0' '-Dspark.rpc.message.maxSize=512' -Dspark.yarn.app.container.log.dir=/var/log/hadoop-yarn/userlogs/application_1650653302475_0004/container_1650653302475_0004_01_000002 -XX:OnOutOfMemoryError='kill %p' org.apache.spark.executor.YarnCoarseGrainedExecutorBackend --driver-url spark://CoarseGrainedScheduler@hw2-m.c.csee4121-339916.internal:44927 --executor-id 2 --hostname hw2-w-0.c.csee4121-339916.internal --cores 2 --app-id application_1650653302475_0004 --resourceProfileId 0 --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000002/__app__.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000002/com.databricks_spark-xml_2.12-0.14.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000002/commons-io_commons-io-2.8.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000002/org.glassfish.jaxb_txw2-2.3.4.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000002/org.apache.ws.xmlschema_xmlschema-core-2.2.5.jar > /var/log/hadoop-yarn/userlogs/application_1650653302475_0004/container_1650653302475_0004_01_000002/stdout 2> /var/log/hadoop-yarn/userlogs/application_1650653302475_0004/container_1650653302475_0004_01_000002/stderr\n",
      "Last 4096 bytes of stderr :\n",
      "\n",
      "\n",
      ".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/04/22 21:45:50 WARN org.apache.spark.deploy.yarn.YarnAllocator: Container from a bad node: container_1650653302475_0004_01_000005 on host: hw2-w-0.c.csee4121-339916.internal. Exit status: 134. Diagnostics: [2022-04-22 21:45:50.654]Exception from container-launch.\n",
      "Container id: container_1650653302475_0004_01_000005\n",
      "Exit code: 134\n",
      "\n",
      "[2022-04-22 21:45:50.655]Container exited with a non-zero exit code 134. Error file: prelaunch.err.\n",
      "Last 4096 bytes of prelaunch.err :\n",
      "/bin/bash: line 1:  4768 Aborted                 /usr/lib/jvm/temurin-8-jdk-amd64/bin/java -server -Xmx5739m -Djava.io.tmpdir=/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000005/tmp '-Dspark.driver.port=44927' '-Dspark.ui.port=0' '-Dspark.rpc.message.maxSize=512' -Dspark.yarn.app.container.log.dir=/var/log/hadoop-yarn/userlogs/application_1650653302475_0004/container_1650653302475_0004_01_000005 -XX:OnOutOfMemoryError='kill %p' org.apache.spark.executor.YarnCoarseGrainedExecutorBackend --driver-url spark://CoarseGrainedScheduler@hw2-m.c.csee4121-339916.internal:44927 --executor-id 4 --hostname hw2-w-0.c.csee4121-339916.internal --cores 2 --app-id application_1650653302475_0004 --resourceProfileId 0 --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000005/__app__.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000005/com.databricks_spark-xml_2.12-0.14.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000005/commons-io_commons-io-2.8.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000005/org.glassfish.jaxb_txw2-2.3.4.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000005/org.apache.ws.xmlschema_xmlschema-core-2.2.5.jar > /var/log/hadoop-yarn/userlogs/application_1650653302475_0004/container_1650653302475_0004_01_000005/stdout 2> /var/log/hadoop-yarn/userlogs/application_1650653302475_0004/container_1650653302475_0004_01_000005/stderr\n",
      "Last 4096 bytes of stderr :\n",
      "\n",
      "\n",
      "[2022-04-22 21:45:50.656]Container exited with a non-zero exit code 134. Error file: prelaunch.err.\n",
      "Last 4096 bytes of prelaunch.err :\n",
      "/bin/bash: line 1:  4768 Aborted                 /usr/lib/jvm/temurin-8-jdk-amd64/bin/java -server -Xmx5739m -Djava.io.tmpdir=/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000005/tmp '-Dspark.driver.port=44927' '-Dspark.ui.port=0' '-Dspark.rpc.message.maxSize=512' -Dspark.yarn.app.container.log.dir=/var/log/hadoop-yarn/userlogs/application_1650653302475_0004/container_1650653302475_0004_01_000005 -XX:OnOutOfMemoryError='kill %p' org.apache.spark.executor.YarnCoarseGrainedExecutorBackend --driver-url spark://CoarseGrainedScheduler@hw2-m.c.csee4121-339916.internal:44927 --executor-id 4 --hostname hw2-w-0.c.csee4121-339916.internal --cores 2 --app-id application_1650653302475_0004 --resourceProfileId 0 --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000005/__app__.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000005/com.databricks_spark-xml_2.12-0.14.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000005/commons-io_commons-io-2.8.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000005/org.glassfish.jaxb_txw2-2.3.4.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000005/org.apache.ws.xmlschema_xmlschema-core-2.2.5.jar > /var/log/hadoop-yarn/userlogs/application_1650653302475_0004/container_1650653302475_0004_01_000005/stdout 2> /var/log/hadoop-yarn/userlogs/application_1650653302475_0004/container_1650653302475_0004_01_000005/stderr\n",
      "Last 4096 bytes of stderr :\n",
      "\n",
      "\n",
      ".\n",
      "22/04/22 21:45:50 WARN org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 4 for reason Container from a bad node: container_1650653302475_0004_01_000005 on host: hw2-w-0.c.csee4121-339916.internal. Exit status: 134. Diagnostics: [2022-04-22 21:45:50.654]Exception from container-launch.\n",
      "Container id: container_1650653302475_0004_01_000005\n",
      "Exit code: 134\n",
      "\n",
      "[2022-04-22 21:45:50.655]Container exited with a non-zero exit code 134. Error file: prelaunch.err.\n",
      "Last 4096 bytes of prelaunch.err :\n",
      "/bin/bash: line 1:  4768 Aborted                 /usr/lib/jvm/temurin-8-jdk-amd64/bin/java -server -Xmx5739m -Djava.io.tmpdir=/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000005/tmp '-Dspark.driver.port=44927' '-Dspark.ui.port=0' '-Dspark.rpc.message.maxSize=512' -Dspark.yarn.app.container.log.dir=/var/log/hadoop-yarn/userlogs/application_1650653302475_0004/container_1650653302475_0004_01_000005 -XX:OnOutOfMemoryError='kill %p' org.apache.spark.executor.YarnCoarseGrainedExecutorBackend --driver-url spark://CoarseGrainedScheduler@hw2-m.c.csee4121-339916.internal:44927 --executor-id 4 --hostname hw2-w-0.c.csee4121-339916.internal --cores 2 --app-id application_1650653302475_0004 --resourceProfileId 0 --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000005/__app__.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000005/com.databricks_spark-xml_2.12-0.14.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000005/commons-io_commons-io-2.8.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000005/org.glassfish.jaxb_txw2-2.3.4.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000005/org.apache.ws.xmlschema_xmlschema-core-2.2.5.jar > /var/log/hadoop-yarn/userlogs/application_1650653302475_0004/container_1650653302475_0004_01_000005/stdout 2> /var/log/hadoop-yarn/userlogs/application_1650653302475_0004/container_1650653302475_0004_01_000005/stderr\n",
      "Last 4096 bytes of stderr :\n",
      "\n",
      "\n",
      "[2022-04-22 21:45:50.656]Container exited with a non-zero exit code 134. Error file: prelaunch.err.\n",
      "Last 4096 bytes of prelaunch.err :\n",
      "/bin/bash: line 1:  4768 Aborted                 /usr/lib/jvm/temurin-8-jdk-amd64/bin/java -server -Xmx5739m -Djava.io.tmpdir=/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000005/tmp '-Dspark.driver.port=44927' '-Dspark.ui.port=0' '-Dspark.rpc.message.maxSize=512' -Dspark.yarn.app.container.log.dir=/var/log/hadoop-yarn/userlogs/application_1650653302475_0004/container_1650653302475_0004_01_000005 -XX:OnOutOfMemoryError='kill %p' org.apache.spark.executor.YarnCoarseGrainedExecutorBackend --driver-url spark://CoarseGrainedScheduler@hw2-m.c.csee4121-339916.internal:44927 --executor-id 4 --hostname hw2-w-0.c.csee4121-339916.internal --cores 2 --app-id application_1650653302475_0004 --resourceProfileId 0 --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000005/__app__.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000005/com.databricks_spark-xml_2.12-0.14.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000005/commons-io_commons-io-2.8.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000005/org.glassfish.jaxb_txw2-2.3.4.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000005/org.apache.ws.xmlschema_xmlschema-core-2.2.5.jar > /var/log/hadoop-yarn/userlogs/application_1650653302475_0004/container_1650653302475_0004_01_000005/stdout 2> /var/log/hadoop-yarn/userlogs/application_1650653302475_0004/container_1650653302475_0004_01_000005/stderr\n",
      "Last 4096 bytes of stderr :\n",
      "\n",
      "\n",
      ".\n",
      "22/04/22 21:45:50 ERROR org.apache.spark.scheduler.cluster.YarnScheduler: Lost executor 4 on hw2-w-0.c.csee4121-339916.internal: Container from a bad node: container_1650653302475_0004_01_000005 on host: hw2-w-0.c.csee4121-339916.internal. Exit status: 134. Diagnostics: [2022-04-22 21:45:50.654]Exception from container-launch.\n",
      "Container id: container_1650653302475_0004_01_000005\n",
      "Exit code: 134\n",
      "\n",
      "[2022-04-22 21:45:50.655]Container exited with a non-zero exit code 134. Error file: prelaunch.err.\n",
      "Last 4096 bytes of prelaunch.err :\n",
      "/bin/bash: line 1:  4768 Aborted                 /usr/lib/jvm/temurin-8-jdk-amd64/bin/java -server -Xmx5739m -Djava.io.tmpdir=/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000005/tmp '-Dspark.driver.port=44927' '-Dspark.ui.port=0' '-Dspark.rpc.message.maxSize=512' -Dspark.yarn.app.container.log.dir=/var/log/hadoop-yarn/userlogs/application_1650653302475_0004/container_1650653302475_0004_01_000005 -XX:OnOutOfMemoryError='kill %p' org.apache.spark.executor.YarnCoarseGrainedExecutorBackend --driver-url spark://CoarseGrainedScheduler@hw2-m.c.csee4121-339916.internal:44927 --executor-id 4 --hostname hw2-w-0.c.csee4121-339916.internal --cores 2 --app-id application_1650653302475_0004 --resourceProfileId 0 --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000005/__app__.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000005/com.databricks_spark-xml_2.12-0.14.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000005/commons-io_commons-io-2.8.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000005/org.glassfish.jaxb_txw2-2.3.4.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000005/org.apache.ws.xmlschema_xmlschema-core-2.2.5.jar > /var/log/hadoop-yarn/userlogs/application_1650653302475_0004/container_1650653302475_0004_01_000005/stdout 2> /var/log/hadoop-yarn/userlogs/application_1650653302475_0004/container_1650653302475_0004_01_000005/stderr\n",
      "Last 4096 bytes of stderr :\n",
      "\n",
      "\n",
      "[2022-04-22 21:45:50.656]Container exited with a non-zero exit code 134. Error file: prelaunch.err.\n",
      "Last 4096 bytes of prelaunch.err :\n",
      "/bin/bash: line 1:  4768 Aborted                 /usr/lib/jvm/temurin-8-jdk-amd64/bin/java -server -Xmx5739m -Djava.io.tmpdir=/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000005/tmp '-Dspark.driver.port=44927' '-Dspark.ui.port=0' '-Dspark.rpc.message.maxSize=512' -Dspark.yarn.app.container.log.dir=/var/log/hadoop-yarn/userlogs/application_1650653302475_0004/container_1650653302475_0004_01_000005 -XX:OnOutOfMemoryError='kill %p' org.apache.spark.executor.YarnCoarseGrainedExecutorBackend --driver-url spark://CoarseGrainedScheduler@hw2-m.c.csee4121-339916.internal:44927 --executor-id 4 --hostname hw2-w-0.c.csee4121-339916.internal --cores 2 --app-id application_1650653302475_0004 --resourceProfileId 0 --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000005/__app__.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000005/com.databricks_spark-xml_2.12-0.14.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000005/commons-io_commons-io-2.8.0.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000005/org.glassfish.jaxb_txw2-2.3.4.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1650653302475_0004/container_1650653302475_0004_01_000005/org.apache.ws.xmlschema_xmlschema-core-2.2.5.jar > /var/log/hadoop-yarn/userlogs/application_1650653302475_0004/container_1650653302475_0004_01_000005/stdout 2> /var/log/hadoop-yarn/userlogs/application_1650653302475_0004/container_1650653302475_0004_01_000005/stderr\n",
      "Last 4096 bytes of stderr :\n",
      "\n",
      "\n",
      ".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 237:>                (0 + 4) / 5][Stage 242:>                (0 + 2) / 5]\r"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    newdf = df.join(newdf, df._c0 == newdf.article, 'inner')\n",
    "    newdf = newdf.groupBy(['_c1']).sum('contribution').rdd.map(lambda x: (x[0], 0.15 + 0.85 * x[1])).toDF(['article', 'rank'])\n",
    "    newdf = df_count.join(newdf, df._c0 == newdf.article, 'left')\n",
    "    newdf = newdf.na.fill(0.15)\n",
    "    newdf = newdf.rdd.map(lambda x:(x[0], x[1], x[3], x[3]/x[1])).toDF(['article', 'count', 'rank', 'contribution'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63e094d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "newdf = newdf.select('article', 'rank').orderBy('article', 'rank')\n",
    "newdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2945d12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "newdf.repartition(10).write.option(\"delimiter\", \"\\t\").csv('p1t3_small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3256ab7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "newdf.limit(5).toPandas().to_csv('/home/jz3313/hw2/p1t3/p1t3.csv', sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
